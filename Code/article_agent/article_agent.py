import os
import time
from dotenv import load_dotenv
from typing import Optional, List
from langchain_groq import ChatGroq
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.messages import HumanMessage, AIMessage


try:
    # for main pipeline
    from .agent_tools import search_duckduckgo, fetch_wikipedia_context 
except ImportError:
    # for direct script execution
    from agent_tools import search_duckduckgo, fetch_wikipedia_context



class ArticleAgent:
    def __init__(self, list_of_tools: list = [fetch_wikipedia_context, search_duckduckgo]):
        """
        Initialize the ArticleAgent with the large language model, Wikipedia retriever, and DuckDuckGo search.
        """
        # Load environment variables
        load_dotenv()

        # Get the API key for the Groq language model
        self.gq_token: Optional[str] = os.getenv("GROQ_API_KEY")

        # Initialize the Groq language model
        self.llm = ChatGroq(
            api_key=self.gq_token,
            model="llama3-8b-8192",
            temperature=0.5,
            max_tokens=None,
            timeout=None,
            max_retries=2,
        )

        self.tools = list_of_tools

        self.llm_with_tools = self.llm.bind_tools(self.tools)


    def get_information_with_sources(self, task: str = "") -> AIMessage:
        """
        Get information based on the task and instruction provided, using Wikipedia and DuckDuckGo as tools.

        Args:
            task (str): The task to be performed, in our context it is advised to mention brand and type in the task (e.g., "Write a introductory paragraph about a BMW M5.").
            prior_responses (str): Prior responses to be used as context.

        Returns:
            str: The answer generated by the model.
        """

        # Create the prompt
        query = f"{task}"

        messages = [HumanMessage(query)]
        ai_msg = self.llm_with_tools.invoke(messages)
        # If the model does not call any tools, retry once.
        if len(ai_msg.tool_calls) == 0:
            time.sleep(1) # To avoid getting blocked by rate limiting
            ai_msg = self.llm_with_tools.invoke(messages)

        print(f"Number of tool calls: {len(ai_msg.tool_calls)}")
        if len(ai_msg.tool_calls) == 0:
            return None

        messages.append(ai_msg)

        for tool_call in ai_msg.tool_calls:
            selected_tool = {"search_duckduckgo": search_duckduckgo, "fetch_wikipedia_context": fetch_wikipedia_context}[tool_call["name"].lower()]
            tool_msg = selected_tool.invoke(tool_call)
            messages.append(tool_msg)

        return self.llm_with_tools.invoke(messages)
    
    def get_information_with_sources_fallback(self, brand: None, type: None, task: str, instruction: str = "Perform the task based only on the context provided. Look at the prior responses as a reference.", prior_responses: str = "") -> AIMessage:
        """
        Get information based on the task and instruction provided, using all tools.

        Args:
            task (str): The task to be performed.
            instruction (str): The instruction to be displayed to the model.
            prior_responses (str): The prior responses to be used as reference.

        Returns:
            str: The answer generated by the model.
        """
        tool_res_0 = self.tools[0].invoke({"brand": brand, "type": type})
        tool_res_1 = self.tools[1].invoke({"brand": brand, "type": type})
        

        prompt = f"{instruction} \nPrior Responses: {prior_responses} \nContext: \n{tool_res_0}\n{tool_res_1} \nTask: {task}"
        

        return self.llm.invoke(prompt)

    
    def create_paragraphs(self, tasks: List[str], brand: str = None, car_type: str = None) -> List[str]:
        """
        Create paragraphs for the given tasks.

        Args:
            tasks (List[str]): The list of tasks for which paragraphs need to be created.

        Returns:
            List[str]: The list of paragraphs created for the given tasks.
        """
        paragraphs = []
        responses = ""
        for task in tasks:
            print(f"\n\nTask: {task}")
            paragraph = self.get_information_with_sources(task=task)
            if paragraph is None:
                print("Model did not call any tools and failed to generate a response. Fallback to using all tools.")
                paragraph = self.get_information_with_sources_fallback(brand, car_type, task, prior_responses=responses)
            paragraphs.append(paragraph.content)
        return paragraphs
    
    def get_information(self, context: str, instruction: str) -> str:
        """
        Get information based on the task and instruction provided.

        Args:
            context (str): The context to be used for generating the answer.
            instruction (str): The instruction to be displayed to the model.

        Returns:
            str: The answer generated by the model.
        """
        
        prompt = ChatPromptTemplate.from_template(
            f"""
            {instruction}
            Context: {{context}}
            """
        )

        # Define the processing chain
        chain = (
            {"context": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )

        # Generate the answer
        return chain.invoke(context)

    def create_image_descriptions(self, paragraphs: List[str]) -> List[str]:
        """
        Create descriptions for the given images based on a string.

        Args:
            paragraphs (List[str]): The list of paragraphs based on which the image descriptions need to be created.

        Returns:
            List[str]: The list of image descriptions created for the given paragraphs.
        """
        image_descriptions = []
        views = ["front", "back", "side", "interior"]
        for i, paragraph in enumerate(paragraphs):
            view = views[i % len(views)]
            # for a diffusion model, create the description of the image based on the paragraph
            image_description = self.get_information(context=paragraph, instruction=f"Create a description of an image based on the context provided. Only describe the image. The image should be a {str(view)} view of the car.")
            image_descriptions.append(image_description)
        return image_descriptions

    def create_image_subtitles(self, descriptions: List[str]) -> List[str]:
        """
        Create image subtitles based on image descriptions

        Args:
            descriptions (List[str]): The list of paragraphs based on which the image descriptions need to be created.

        Returns:
            List[str]: The list of image descriptions created for the given paragraphs.
        """
        image_descriptions = []
        for description in descriptions:
            # for a diffusion model, create the description of the image based on the paragraph
            image_description = self.get_information(context=description, instruction="Create a subtitle for an image based on the image description provided in the context. Only give me the subtitle.")
            image_descriptions.append(image_description)
        return image_descriptions

if __name__ == "__main__":
    tools = [fetch_wikipedia_context, search_duckduckgo]
    agent = ArticleAgent(list_of_tools=tools)
    brand = 'BMW'
    car_type = 'SUV'
    tasks = [
        f"Write a introductory paragraph for an article about a {brand} {car_type}.",
        f"Write a paragraph for an article about a new {car_type} offered by {brand}.",
        f"Write a paragraph for an article about the history of {brand}.",
        f"Write a paragraph for an article about the innovations of the {car_type} of {brand}."
    ]
    paragraphs = agent.create_paragraphs(tasks)
    print(paragraphs)